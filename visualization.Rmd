# Visualization 

## Overview  

Curators: Libby Mohr^1^, Matthew Brousil^2^, Kelly Heilman^3^, Hassan Moustahfid^4^, Leah Johnson^5^, David LeBauer^3^, Rob Kooper^6^, Cee Nell^7^, Josh Cullen^8^, Jake Zwart^7^, Jody Peters^9^, Quinn Thomas^5^, Mike Dietze^10^

*^1^University of Montana, ^2^Washington State University, ^3^University of Arizona, ^4^NOAA, ^5^Virginia Tech, ^6^National Center for Supercomputing Applications, ^7^USGS, ^8^Florida State University, ^9^University of Notre Dame, ^10^Boston University*


“A picture is worth a thousand words” or so goes the old adage.

At the end of any data gathering endeavor, one is faced with the task of dissemination. This step determines how the end user consumes the information buried within the data. Often these data sets are complex and require creative strategies to communicate information accurately and effectively.  Science, policy and planning rely on reliable and unbiased communications. Data visualizations and graphics are a powerful means to communicate. They have great impact on how we perceive environmental problems, their solutions, and if we consider policies legitimate.  Over the last two decades, more and more studies have demonstrated that visualization plays a role in data-communication, influences decision making, public perception, public participation, and knowledge cocreation ([Metze 2020](https://doi.org/10.1080/1523908X.2020.1798751)).
A famous example of a great data visualization is Charles Joseph Minard’s [diagram of Napoleon’s march](https://www.edwardtufte.com/tufte/posters) to Moscow, which clearly shows the disastrous number of lives lost in this military campaign. Such an image readily conveys a message “at a glance” that sticks to memory and is difficult to forget. Another example of influential visualizations is the diagram of the ‘Burning Embers’ from the IPCC report in 2001 (updated in 2009). This diagram visualizes the risks coming from the heating up of the earth (see Fig. 1 in Smith et al 2009). Studies show how these embers have been adapted and contested over time ([Wardekker & Lorenz 2019](https://doi.org/10.1007/s10584-019-02522-6)).

***Placeholder for Burning Embers Figure***

Data visualization has a long history in scientific communication. Simple forms include pie charts, line graphs and more complex network diagrams. Newer techniques use larger datasets and allow users to interact with data to create their own visualizations “on demand”. For example, the large dataset that pertains to COVID-19 and its impact on various populations across the globe clearly demonstrates the impact of data visualization on science on policy ([Johns Hopkins COVID-19 Dashboard](coronavirus.jhu.edu)).

Data visualization requires an appreciation for how to convey relationships, categories, and magnitude through the creative use of lines, colors, symbols, position and size. Data visuals help tell a story, starting with a compelling problem or question, using data to provide perspective, and giving the reader some insight or solution. Yet creators must respect the limits in datasets. For example, maps of climate change (see figure SPM.1 in www.ipcc.ch) show bands of color with projected changes in temperature or precipitation, but they are limited by the scarcity of weather observation stations across the developing world.

To inform policy, data visualization is beginning to enrich our understanding of the challenges facing society. Evidence-based illustrations, or infographics, help convey complex policy issues and the potential trade-offs in greater depth than long reports or other media ([Mclnerny et al. 2014](https://doi.org/10.1016/j.tree.2014.01.003)). Finally, when subject matter is intangible (e.g., due to scale, complexity, or abstraction), visualizations have a fundamental role in exploring information and generating understanding. In addition to an open scientific infrastructure, visualization and graphics should be among the main priorities for developing modern science and science policy.

The following Task View first provides guiding principles for creating visualizations and applications with static or interactive features, then provides examples and tools to create static, animated, interactive, and spatial visuals as well as resources for visualizing uncertainty. 

## Guiding Principles

### Overview
Project design, co-development, and sustainability, are all important aspects to consider when creating visualizations.  The following principles can apply to a range of visualizations and applications ranging from scientific publications to user interface and decision support applications.  Although often unseen by users, how one generates the information and visualizations used to convey that information is just as important as the science behind the information being shared.  Here is an [EFI Bibliography Zotero Library](https://www.zotero.org/groups/2545778/ecological_forecasting_initiative_bibliography/library) with books and papers on visualization best practices. In Zotero, use the Filter Tags section in the lower left-hand corner to select "EFI Visualization Paper" to bring up the references. Additional resources, specifically for web applications for visualizing scientific data can be found in this [scientificwebapps Zotero Bibliography](http://zotero.org/groups/2845330/scientificwebapps).

### Design
When developing visualizations determine the intended purpose, use case, and motivation for the resources being developed. Will you be using the resource to conduct exploratory data analysis, to be used in a publication, or to allow an audience that is internal or external to the project to interact with the output? Think about who wants the information, what information is important, how important is that information, and what outcome or takeaways do you want the audience to grasp.  Your target audience and intended outcomes will shape the development process and the design of the visualization tool.
One way to brainstorm visualizations is to think about user stories, a concept from computer science. User stories are informal, general explanations of a software feature (but apply to visualizations as well) written from the perspective of the end user. See [Max Rehkopf’s 2022 user story template and examples](https://www.atlassian.com/agile/project-management/user-stories) to further consider how a visualization, app, or tool provides value to the end user.

The following table provides suggestions and considerations when working with end-users, thinking about the life expectancy and sustainability of a visualization or application, using interfaces, communicating with end-users through visualization or application, and what kind of maintenance is needed. This table comes from the [sciwebapps project](https://github.com/trashbirdecology/sciwebapps/tree/main/learning-resources) that is creating an open source and community-driven repository for resources, information, discussions, and suggested practices for creating, communicating, and improving Scientific Web Applications. 

#### Considerations for end users
**Table 1: Considerations for end users, life expectancy and sustainability of the app, interface outputs, communicating to end-users and feedback, and app maintenance and updates.**

|**Consideration**  | **Description** | **Recommendations**  | **Benefits** | **Consequence of Ignoring** | 
|------------- | --------------------------------- | ------------------------- | -------------------------------------------- | ---------------------- |
| End users | Who is my end user? (Arugably the most important questions) |     | Identify potential communities with which to communicate throughout the process. Design the interface for the anticipated end user. Reach out to the anticipated end user to identify needs, skills, etc. Make it easier to streamline the dissemination process. | Creating a product that has no clear end user | 
| End users | What are the needs of my end users? | Ask potential end users. | Improve chances of actually meeting the needs of end users. Improve broader impacts of your research. | Fail to meet the needs of the end users. | 
| End users | What are the skills or prior knowledge of my end user? | Ask end users or always assume that end users have the minimal amount of skills or prior knowledge, but don't "dumb it down". | Make your interface easier to use by stakeholders. Make the content more easily interpretable. Opportunity to create different options for end users with varying skills, while keeping the barrier to entry low for users without certain skills. | Isolating end users without necessary skills or knowledge may lead to non-adoption. | 
| Life expectancy and sustainability | How long will this application be relevant to end users?  |  |  |  | 
| Life expectancy and sustainability| How will I ensure the application is available for that period of time? |  |  |  | 
| Life expectancy and sustainability | What are the costs (time, money, bytes) associated with hosting or storing for this period of time? |  |  |  | 
| Life expectancy and sustainability | Where will this application be located in 1 years time? 5? 10? | Consider storing the source code for your application within a trusted digital repository. Consider using persistent identifiers for released versions. Be certain you will always have access to the host location (e.g., website), and if there are associated fees consider whether you anticipate to always pay the hosting fees. | Releasing the initial version and each thereafter requires only a single location (URL, URI, DOI) to maintain and to share. | Changing the location (e.g., URL) of an application will be to the detriment of the usage of your application. If you publish the first release of this software inside a research journal article, but change the location some months or years down the road, it will render the intial reference useless. Will also add another layer to the findability of your application. | 
| Interface outputs | What is the purpose of the interface? |  |  |  | 
| Interface outputs | How will information be exported from the interface? |  |  |  | 
| Communication | How will I communicate to potential end-users? | If you have identified the end-user types or individuals, then a communication plan becomes more constrained. Consider how effective communication through various outlets will be. Will a research article reach your intended audience? How about a Tweet? How about an email to certain individuals? |  |  | 
| Communication | Will I provide an option for feedback on the interface? If so, how? | The easier it is for the end user to provide feedback, the higher the probability is that the end user will supply it. (surely there must be some statistics on this..) |  |  | 
| Maintenance and updating | What are the costs associated with maintaining the source code and user interface? |  |  |  | 

### Co-development 
Depending on the type of visualization product you are creating and your audience, you may be collaborating with other users or parties on project development. If so, it is important to consider the co-development process. Co-development or co-production of a visualization or application takes place when Information Users and Information Providers collaborate in the generation of scientific resources. Ideally the co-development process aims to build and sustain partnerships, acknowledging differences in what each party needs out of the partnership and the project, and what the partners’ strengths and limitations are regarding their contributions. Co-production can take different forms depending on the project or funding ranging from projects with limited to no community participation (e.g., contractual) to community members having authority over the research process (e.g., Indigenous) ([David-Chavez and Gavin, 2018](https://iopscience.iop.org/article/10.1088/1748-9326/aaf300/meta)). 
Additional information about co-production definitions, papers, info sheets, and frameworks and assessment tools that was shared by three panelists from a seminar on co-production hosted by the EFI Partners & Knowledge Transfer Working Group in May 2021 can be [found here](https://ecoforecast.org/knowledge-transfer-partners/co-production-actionable-science-panel/#co-productionresources).


### Product Sustainability 
Best practices include identifying the intended lifespan of the product and the available resources (e.g. time, funding, computing resources) for maintaining and hosting the product. An important consideration for public-facing tools is how much traffic they can handle and what resources are needed to maintain or increase their scale or user base.


## How We Make Visuals
### Digital Accessibility (a11y)
Digital accessibility, also referred to as ‘a11y’, is used in Web development to enable as many people as possible to use Web sites no matter an individual’s physical and cognitive abilities. See [Burnett et al.2021](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009574) for a brief discussion of a11y with respect to scientific web applications. 
Table 2 below provides a list of a11y resources with general information, standards and evaluation, assessment tools, and communities of practice that are useful to explore when creating web applications or other user interfaces.
 
#### a11y resources
**Table 2: a11y resources with general information, standards and evaluation, assessment tools, and communities of practice that are useful to explore when creating web applications or other user interfaces.**

|**Resources Type**  | **Consideration** | **Website**  | 
|----------------------- | ------------------------------------------------------------- | -------------------------------------- | 
| General information | U.S. federal government-wide IT accessibility program. Includes recommendations, and standards for creating accessible digital products. Also provides many tools for evaluating digital products for accessibility. | https://www.section508.gov/ |
| General information | Open access front-end checklist for website design by David Dias. The .io webpage includes a DIY checklist and report for evaluating websites. | https://frontendchecklist.io/; https://github.com/thedaviddias/Front-End-Checklist#accessibility |
| General information | A11Y Project. A open-source resource and community of practice for advancing accessibility (A11Y) in the digital space. Provides digestable information, tips, and tools for creating accessible digital products. | https://a11yproject.com/ | 
| General information | Yale University’s curated list of tips, techniques, and resources for web accessibility. | https://usability.yale.edu/web-accessibility/articles/links | 
| General information | Tutorials, documentation, and resources for web accessibility curated and hosted by Mozilla. | https://developer.mozilla.org/en-US/docs/Web/Accessibility | 
| Standards and evaluation | A quick start guide/evaluation of a product from W3C | https://www.w3.org/WAI/test-evaluate/preliminary/ | 
| Standards and evaluation | The Worldwide Web Consortium’s (W3C) Web Content Accessibility Guidelines (WCAG) is an eminent standard (recommendations) for web accessibility. These guidelines provide self-evaluation criterion for meeting one of three standards in order of less to more accessible: A, AA, or AAA. | https://www.levelaccess.com/wcag-2-1-in-amp/; https://www.w3.org/TR/WCAG21/ (guidelines v2.1) | 
| Assessment tool | Web Accessibility Evaluation Tool (WAVE) for evaluating websites for accessibility. | https://wave.webaim.org/ | 
|Assessment tool | Functional Accessibility Evaluator (University of Illinois). An open source tool for evaluating websites for Level A and AA WCAG standards. | https://fae.disability.illinois.edu/ | 
| Assessment tool | Section 508 ICT manual baseline testing for accessibility |  https://github.com/Section508Coordinators/ICTTestingBaseline | 
| Community of Practice | U.S. federal government accessibility community of practice | https://www.cio.gov/about/members-and-leadership/accessibility-cop/ | 
| Community of Practice | Worldwide Web Consortium (W3C) Web Accessibility Initiative (WAI) | https://www.w3.org/WAI/ | 

#### Color Vision Evaluation and Accessibility Tools
* Tools for evaluating graphics with color vision simulators:
  + [Color Oracle](https://colororacle.org/) standalone software
  + [Colorblindly](https://chrome.google.com/webstore/detail/colorblindly/floniaahmccleoclneebhhmnjgdfijgg?hl=en) browser tool 
  + [Colorspace](https://cran.r-project.org/web/packages/colorspace/vignettes/colorspace.html) R package 

* Tools for creating colorblind friendly graphics include: 
  + [Color Brewer](https://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3) provides color options for making maps in R with a range of data classes in multiple color schemes and with colorblind, printer and photocopy safe options 
  + Viridis package in R provide a series of color maps that are designed to improve graph readability for readers with common forms of color blindness and/or color vision deficiency
      + [Tutorial](https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html)
      + [Package](https://cran.r-project.org/web/packages/viridis/viridis.pdf)
  + [Colorspace](https://cran.r-project.org/web/packages/colorspace/vignettes/colorspace.html) R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualizations


#### Alternative Text
Alternative text are written descriptions of images and videos that can be read out loud so that the visual is not required. Captions or transcripts may be necessary for video animations with sound. See [Writing Alt Text for Data Visualization](https://nightingaledvs.com/writing-alt-text-for-data-visualization/) for suggestions on how to write alt text for different types of data visualization, how to add alt text in a number of applications, and links to other resources

#### Motion Sensitivity
* To accommodate motion sensitivity, the WCAG advises: “For any moving, blinking or scrolling information that (1) starts automatically, (2) lasts more than five seconds, and (3) is presented in parallel with other content, there is a mechanism for the user to pause, stop, or hide it unless the movement, blinking, or scrolling is part of an activity where it is essential.” 
* Video animations is be preferred over GIFs for more complex animations because they give playback control to users, do not autoplay or loop infinitely, and can be easily opted out of. Avoiding flashes, bouncing, and slower animations with short durations helps make motion more accessible. 

#### Accessibility Considerations for Interactive Visualizations
* Some interactive features can be difficult to navigate for people navigating with a keyboard or using magnification software.
* Avoid making important information only available on hover
* Display pop-up content upon both hovering with a pointer and focusing with a keyboard
* More tips about pop-up content displayed by mouse hovers and keyboard focus [here](https://accessuse.eu/en/Content-hover-focus.html) 

### Static Visuals
Static visuals are those that don’t change with time or user-input. Such plots are useful for exploratory data analysis (e.g. deciding if and how to include variables in a forecast model), visualizing forecasts and associated uncertainty (see the Uncertainty Visualization Section **NEED TO LINK TO THIS SECTION ONCE THE BOOKDOWN IS MADE!**), and assessing model performance. Whereas animated and interactive graphics allow for additional complexity and exploration, static visuals are well-suited for clearly conveying simple messages.

Below, we briefly describe common types of static plots used in forecasting. For each plot type, we list the tools that can be used to make them. **We focus on tools in R, specifically those within base R and the [ggplot2](https://ggplot2.tidyverse.org/) ecosystem.** 
Additional references for R, Python, and Julia are provided at the end of this section.

For visualizing data in **Python**, we recommend checking out the commonly-used [Matplotlib](https://matplotlib.org/stable/index.html), [Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#), and [Seaborn](https://seaborn.pydata.org/) libraries. 

In **Julia**, the [Plots.jl](https://docs.juliaplots.org/stable/) metapackage provides a common interface to several plotting [backends](https://docs.juliaplots.org/stable/backends/) and the [StatsPlots](https://github.com/JuliaPlots/StatsPlots.jl) package provides additional functionality needed to produce many of the plots described below. 

Spreadsheet platforms (e.g. Microsoft Excel and Google sheets) also provide interactive tools for making simple static plots. 

#### Distributions 
When developing forecasts it is often useful to examine the **distribution** of a single variable or parameter. Such visualizations can be used to examine 1) how data are distributed and 2) uncertainty in parameter estimates or other estimated quantities. There are a few different “flavors” of distribution plots, depending on the application.

**Histograms** are generated by breaking the data up into several bins and then counting the number of data points that fall into each bin.

* `hist` function in base R
* `geom_histogram` in [ggplot2](https://ggplot2.tidyverse.org/) 
* `geom_bar() + scale_x_binned()` in [ggplot2](https://ggplot2.tidyverse.org/)
* `stat_histinterval` from the [ggdist](https://mjskay.github.io/ggdist/articles/slabinterval.html#roadmap-it-all-starts-with-slabinterval-) package
* `geom_bin_2d` in [ggplot2](https://ggplot2.tidyverse.org/) - creates a 2D histogram showing joint distribution of two variables by binning observations into squares in a Cartesian plane
* `geom_hex` in [ggplot2](https://ggplot2.tidyverse.org/) - creates a 2D histogram showing joint distribution of two variables by binning observations into hexagons in a Cartesian plane
* `ggMarginal` from the ggMarginal package can add marginal histograms to existing ggplots.

A **Density Plot** is a smoothed, continuous version of a histogram that displays the estimated probability distribution of a variable or parameter. Density plots are often used to visualize Bayesian prior and posterior distributions. When data or MCMC samples are involved, probability density is typically estimated using the “kernel density estimation” method, where the smoothness and shape of the density curve are controlled by the choice of bandwidth parameter and kernel, respectively (see [Wilke, 2019: Visualizing distributions: Histograms and density plots](https://clauswilke.com/dataviz/)).

* `geom_density` in [ggplot2](https://ggplot2.tidyverse.org/) - plots density estimates for a single variable
* `geom_density_2d` in [ggplot2](https://ggplot2.tidyverse.org/) - plots contours resulting from a 2D kernel density estimation
* `geom_function` in [ggplot2](https://ggplot2.tidyverse.org/) - plots a function (e.g. dnorm)
* `geom_area` in [ggplot2](https://ggplot2.tidyverse.org/) - can be used for a filled density plot
* `slab` and `halfeye` stats from the ggdist package

**Dotplots** show the individual observations of a distribution, either as continuous values or as part of binned intervals (similar to histograms). This type of visualization provides the finest scale of visualization for distributions that may be lost when using other common methods (i.e., histograms, density plots, boxplots). **Quantile Dotplots** are similar, except that the data are broken into quantiles, which are then binned and plotted such that each dot represents a single quantile rather than a single observation. Quantile dotplots are a way of visualizing distributions and uncertainty with a “frequency frame”, and have been shown to aid people in making decisions in the face of uncertainty ([Kay et al, 2016](https://dl.acm.org/doi/10.1145/2858036.2858558)).

* `geom_jitter` in [ggplot2](https://ggplot2.tidyverse.org/) - adds small amounts of variation to the location of each point to avoid overplotting when visualizing observations of a quantitative variable.
* `geom_dotplot` in [ggplot2](https://ggplot2.tidyverse.org/) - bins up observations and plots a single point for each observation.
* `stat_dots` from the [ggdist](https://mjskay.github.io/ggdist/articles/slabinterval.html#roadmap-it-all-starts-with-slabinterval-) package - plots a single point for each binned observation by default, or produces a quantile dotplot if the quantiles argument is specified.

**Boxplots** display common summary statistics for a distribution, which include the minimum, first quartile, median, third quartile, and maximum values. The ‘box’ displays the middle 50% of the distribution while the ‘whiskers’ display the remaining 50% in the tails of the distribution. Any values that fall outside of 1.5 times the length of the ‘box’ are typically drawn as points beyond the whiskers and are typically referred to as outliers. Similarly, **interval plots** typically show the median as a point and one or more lines or boxes whose widths represent quantiles of the distribution. Whereas the plots described above are useful for visualizing single distributions, boxplots, interval plots, violin plots, and ridgeline plots can display multiple distributions in the same plot ([Wilke, 2019](https://clauswilke.com/dataviz/)).

* `boxplot` in base R
* `geom_boxplot` in [ggplot2](https://ggplot2.tidyverse.org/)
* `interval` and `pointinterval` from the [ggdist](https://mjskay.github.io/ggdist/articles/slabinterval.html#roadmap-it-all-starts-with-slabinterval-) package create stand-alone interval plots, whereas several other stats from the stat_slabinterval family allow one to add intervals to other plot types, including density plots, violin plots, histograms, and dotplots.

**Violin plots** are an extension of a density plot where the density plot is mirrored and shows the minimum and maximum values, as well as the maximum point density region(s). Since they can show greater detail of a distribution, violin plots have often been used as a replacement for boxplots more recently.

* `geom_violin` in [ggplot2](https://ggplot2.tidyverse.org/)
* `pirateplot` from the [yarrr](https://bookdown.org/ndphillips/YaRrr/pirateplot.html) package
* `stat_eye` from the [ggdist](https://mjskay.github.io/ggdist/articles/slabinterval.html#roadmap-it-all-starts-with-slabinterval-) package

**Ridgeline plots** show offset density plots for multiple variables. This can be useful for making comparisons of a given variable over space or time, as well as for comparing among a number of groups. However, it is not possible to directly compare the values on the y axis among density plots due to the three dimensional effect of this type of plot. Therefore, this method may be more useful when interested in relative (rather than absolute) densities.

* `geom_density_ridges` from the [ggridges](https://wilkelab.org/ggridges/) package
* `stat_halfeye` from the [ggdist](https://mjskay.github.io/ggdist/articles/slabinterval.html#roadmap-it-all-starts-with-slabinterval-) package


#### Point and line plots 
**Scatterplots** are handy for visualizing relationships between two continuous variables. This includes **time series**, where the variable on the x-axis is time. The following tools are commonly used for making scatterplots: 

* The `plot` function from the base package in R defaults to producing a scatter plot 
* With [ggplot2](https://ggplot2.tidyverse.org/), the geometric object `geom_point` can be used

**Line Graphs** connect data points sequentially and are also commonly used for visualizing **time series**. It’s also possible to add lines to existing scatter plots to emphasize connections between the data while emphasizing the data themselves with points. The tools below are often used to create line graphs or add lines to existing plots:

* The `plot` function from the base package in R generates a line plot with the argument `type = “l”`
* The `lines` function in base R adds a line to an existing plot.
* With [ggplot2](https://ggplot2.tidyverse.org/), the geometric object `geom_line` (or `geom_path`) can be used to add lines.

**Pairs Plots** and **correlograms** are useful for quickly visualizing relationships and correlations between several variables at once. These plots are typically used for exploratory data analysis.

* `pairs` function from base R - creates scatterplot for each combination of variables
* `ggpairs` from the GGally package - by default, displays the correlation between each combination of variables in the top right corner, a scatter plot for each combination of variables in the lower left corner, and a density plot for each variable on the diagonal. Several customization options are available.
* `corPlot` from the psych package - displays the correlation between each combination of variables in a box, where the color hue of the box indicates whether the correlation is positive or negative and the color value indicates the strength of the correlation.


#### Barplots and Heatmaps 
Barplots and Heatmaps are both used to visualize and compare quantities among one or more grouping variables. 

**Barplots** encode quantities using bar length, where each bar represents a group. Stacked and grouped barplots allow for comparison among two different categorical variables.

* `barplot` from base R
* `geom_bar` and `geom_col` from [ggplot2](https://ggplot2.tidyverse.org/)

**Heatmaps** encode quantities using color, where the x and y position of each block in the heatmap correspond to the first and second categorical variables, respectively.

* `heatmap` from base R
* `geom_tile` from [ggplot2](https://ggplot2.tidyverse.org/)

**Composite plots** are created by combining multiple plots into the same graphic.

* `facet_wrap` and `facet_grid` in [ggplot2](https://ggplot2.tidyverse.org/) - breaks the data into groups based on one or more grouping variables and displays a plot for each group
* `plot_grid` from the [cowplot](https://wilkelab.org/cowplot/articles/plot_grid.html) package
* The [patchwork](https://patchwork.data-imaginist.com/) package 
* `grid.arrange` from the [gridExtra](https://cran.r-project.org/web/packages/gridExtra/index.html) package


#### References 
**R**

* [Fundamentals of Data Visualization](https://clauswilke.com/dataviz/)
* [From data to Viz | Find the graphic you need](https://www.data-to-viz.com/)
* [Welcome | ggplot2](https://ggplot2.tidyverse.org/)
* [R Graphics Cookbook, 2nd edition](https://r-graphics.org/)
* [3 Data visualisation | R for Data Science](https://r4ds.had.co.nz/data-visualisation.html)
* [28 Graphics for communication | R for Data Science](https://r4ds.had.co.nz/graphics-for-communication.html)

**Python**

* [Introduction to Data Visualization in Python | by Gilbert Tanner](https://towardsdatascience.com/introduction-to-data-visualization-in-python-89a54c97fbed)
* [Chart Visualization — pandas 1.3.4 documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#)
* [Usage Guide — Matplotlib 3.4.3 documentation](https://matplotlib.org/stable/tutorials/introductory/usage.html#sphx-glr-tutorials-introductory-usage-py)
* [seaborn: statistical data visualization — seaborn 0.11.2 documentation](https://seaborn.pydata.org/)

**Julia**

* [Plotting backends](https://docs.juliaplots.org/latest/backends/#backends)
* [StatsPlots](https://github.com/JuliaPlots/StatsPlots.jl)


### Animated Visuals
Gif, video, and other animations are a powerful way to communicate complexity and patterns where static visualizations may fall short. Animations provide an additional dimension that can allow an audience to [see progression in data over time](https://ebird.org/science/status-and-trends/abundance-animations) or depth, [track changes](https://observablehq.com/@d3/bar-chart-race), or [layer in additional information to support narration](https://labs.waterdata.usgs.gov/visualizations/snow-to-flow/index.html#/). This may be useful to avoid overwhelming a viewer and guide the audience’s attention to specific data points. Further, whereas static, 2D representations of 3D objects [are difficult to interpret](https://clauswilke.com/dataviz/no-3d.html), animated representations where the object is rotated and displayed at different angles allow viewers to create [a mental reconstruction](https://www.tylermw.com/3d-maps-with-rayshader/) of the 3D object. Finally, animation can be used to convey uncertainty using hypothetical outcome plots (HOPs), which are animated sequences of plots where each plot represents a random draw from an underlying distribution. Research suggests that HOPs lead to better understanding of uncertainty and more accurate judgments about differences between multiple random variables ([Hullman et al., 2015](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0142444); [Kale et al., 2019](https://ieeexplore.ieee.org/document/8440816)).

#### Animation tools

* [gganimate package](https://gganimate.com/)
  + Transitions define how animations are mapped to data 
  + `transition_time` transitions data through time, with the duration of each frame relative to the distance in time 
  + `transition_reveal` gradually reveals data 
  + `transition_states` animates between distinct stages or groups 
* [rayshader package](https://www.rayshader.com/)
  + Create movies of camera moving around 3D maps and ggplots with `render_movie`. Camera path around visualization can be custom defined. 
* ImageMagick (CLI) / [Magick (R)](https://github.com/ropensci/magick) 
  + Manipulate images (rotate, scale, crop, trim, flip, blur, etc) and stitch into animation (`image_animate` in R).
* [gifski package](https://cran.r-project.org/web/packages/gifski/index.html)
  + Sequence any series of frames into a gif using `gifski` 
* Convert gifs to video 
  + ['@gif and @animate'](https://docs.juliaplots.org/latest/animations/) macros in Julia
    + @gif creates an animated gif file. Use this for simple, one-off animations.
    + @animate returns and Animation object for later processing. Use this for anything complex or when you need full control fo the life-cycle of the animation
  + [ImageIO](https://pypi.org/project/imageio/) - Python package


### Interactive and Reactive Features

**Interactive data visualizations** are particularly useful when you find yourself with more information than can realistically be included in a single visualization. Interactive features give control to the end-user, allowing them to access details associated with a particular plot feature or even customize the data being plotted. Common interactive features include those that allow users to zoom and pan over an image, hover or click on features to access tooltips with additional information, and hover over a single object to highlight the entire group to which it belongs. **Reactive visualizations** are a special type of interactive visualization where user input changes the information or data being displayed. Reactivity can allow users to do things like filter data to visualize subsets of interest, modify which variables are plotted, and customize how the data is plotted (e.g. histogram bin size, color palette).  

Here are some principles to consider when developing interactive research products.

1. Scientists developing interactives should understand their users, uses, and usage (impact). 
2. Interactives should be developed and disseminated in the open whenever possible.
3. Funders should develop and enforce standards for interactives as scholarly products.
4. Organizations and communities of practice should enable discovery by improving findability.
5. Organizations should reward researchers for creating useful interactives through existing incentivization structures.
6. Publishers and funding agencies should create and enact publication standards.

	
#### Interactive tools
* [Plotly](https://plotly.com/) (standard types of plots, 3D plots, etc) is a javascript visualization library with wrappers for R, Python, Julia, Matlab.
  + [ggplotly](https://plotly.com/ggplot2/) is a function within the [plotly](https://plotly.com/r/) R package for making ggplot graphics interactive 
  + Resource for working with plotly in R - [Interactive web-based data visualization with R, plotly, and shiny](https://plotly-r.com/)
* [Highcharter](https://jkunst.com/highcharter/) is an R wrapper for the Highcharts javascript library and its modules. Highcharts is a flexible and customizable javascript charting library and it has a great and powerful API.
  + Examples and details about highcharter can be found [here](https://jkunst.com/highcharter/)
* [Charter](https://github.com/JohnCoene/charter) is an R wrapper for the [Charts](https://www.chartjs.org/) javascript library
* [echarts4r](https://echarts4r.john-coene.com/index.html) is an R wrapper for the [Apache eCharts](https://echarts.apache.org/en/index.html) javascript library
* [ggiraph](https://davidgohel.github.io/ggiraph/index.html) is an R package for making ggplot graphics interactive
* [Dygraphs](https://dygraphs.com/) is an open source JavaScript charting library. It can handle large data sets (plots millions of points without getting bogged down), provides strong support for error bars and confidence intervals, and is highly customizable.
* The [rgl](https://dmurdoch.github.io/rgl/) and [rayshader](https://www.rayshader.com/) packages in R allow the creation of interactive 3D plots.

#### High-level Reactive tools 

High-level reactive tools provide figures or graphs that change as a function of user input.

* [Tableau](https://www.tableau.com/) is a subscription-based visualization tool that’s popular in the data viz community
* [PowerBI](https://powerbi.microsoft.com/en-us/)
* [Observable](https://observablehq.com/)
* [Dash](https://dash.plotly.com/r/introduction) is a framework for building and deploying data apps with customized user interfaces in Python, R, Julia, and F# (experimental). 
* [Shiny](https://shiny.rstudio.com/) is an R package that makes it easy to build interactive web apps straight from R. You can host standalone apps on a webpage or embed them in R Markdown documents or build dashboards. You can also extend your Shiny apps with CSS themes, htmlwidgets, and JavaScript actions.
  + This [webpage of Shiny resources](https://lsw5077.github.io/shiny_workshop/resources.html) provides example apps in Ecology, Conservation, and Epidemiology, links to Shiny and R programming resources, and statistical modeling, a Bayesian course, and Tidymodels
  + EFI hosted a [4-part seminar series](https://ecoforecast.org/workshops/r-shiny-seminar-series/) on R Shiny applications and the associated code needed for the applications. The applications included:
    + [Visualization of Data in Space and Time: An Interactive Framework](https://ecoforecast.org/workshops/r-shiny-seminar-series/#space-time)
    + [Creative Visualization of Model Results and Uncertainty in Shiny](https://ecoforecast.org/workshops/r-shiny-seminar-series/#uncertainty-viz)
    + [Improving Speed of Shiny Apps by Pre-Computing Models](https://ecoforecast.org/workshops/r-shiny-seminar-series/#pre-compute)
    + [A Primer to Creating Interactive Maps with Leaflet in Shiny](https://ecoforecast.org/workshops/r-shiny-seminar-series/#leaflet)
* [Interact.jl](https://github.com/JuliaGizmos/Interact.jl) is a Julia package for creating web-based widgets

#### List of web-application development frameworks
**Table 3: List of web-application development frameworks. This table comes from the Supplement Information in Valle et al. 2019. ^+^ These tools are based on Graphical User Interfaces (GUI) and are stand-alone software. ^§^ These tools were not originally included in Valle 2019.**

|**Name**  | **computer language** | **Websites**  | 
|----------------------- | ------------------------------------------------------------- | -------------------------------------- | 
| Bokeh | Python/Scala/Julia/R | https://bokeh.pydata.org/; http://hafen.github.io/rbokeh/ | 
| Django | Python | https://www.djangoproject.com/ | 
| Flask | Python | http://flask.pocoo.org/ | 
|Vega/Vega-Lite | Python (via Altair)/R (via reticulate) | https://altair-viz.github.io/; https://github.com/vegawidget/altair|
| Plotly/Dash | R/Python/Matlab/Julia | https://plot.ly | 
| Htmlwidgets | R | http://www.htmlwidgets.org/ | 
| Shiny/ShinyDashboard | R | https://shiny.rstudio.com/;https://rstudio.github.io/shinydashboard/ | 
| Leaflet | R/Python (via folium)  | https://rstudio.github.io/leaflet/; https://github.com/python-visualization/folium | 
| Tableau | None^+^ | https://www.tableau.com | 
| RapidMiner | None^+^ | https://docs.rapidminer.com/7.6/server/how-to/create-web-apps/ | 
| PowerBI^§c | None^+^ | https://powerbi.microsoft.com/en-us/what-is-power-bi/ | 
| Spotfire^§^ | None^+^ | https://www.tibco.com/products/tibco-spotfire | 
| Superset^§^ | None^+^ | https://superset.apache.org/ | 


### Geospatial Visuals
Spatial datasets contain information that links the data to physical/geographic locations. Because spatial data has extra information, visualization, modeling, and manipulating spatial data requires special file formats, projections, and geospatial operations. We will briefly describe these here, but refer to existing resources on Geographic Information Systems (GIS) and working with static spatial data. 
[Geocomputation with R](https://geocompr.robinlovelace.net) is an online book on geographic data analysis, visualization and modeling

#### File Formats
Files containing spatial data need to convey the spatial coordinates and how coordinates in geographic space are mapped onto a flat map surface. Thus, these data are often stored in different file formats than non-spatial data. 

* **Vector:** A vector stores spatial data in a vector format (as opposed to gridded), such as in points, lines, and polygons
  + geojson - json or text based standard that is commonly sent with APIs. [geojson.io](http://geojson.io/about.html) is a fast, simple tool to create, change, and publish maps using geojson data
  + [geopackage](https://www.geopackage.org/) - based on SQLite (derived from spatialite and updated for OGC standard compliance)
  + [Shapefile](https://en.wikipedia.org/wiki/Shapefile) - this is widely adopted ArcGIS format; requires multiple files (shp, shx, dbf, etc) to be complete, often combined into a single zip
* **Raster:** Raster file formats store spatial data in pixels along a regular grid.
  + There are a variety of different raster file formats, including GeoTIFF, ASCII, netcdf, cloud optimized geotiff, etc

#### Projections and Coordinate Reference Systems (CRS)
Projections and coordinate reference systems both contain information about how spatial data can be visualized, and where it is, with important differences. 
Geographic Coordinate Reference Systems contain information on how spatial data is projected or placed on the Earth’s surface. 
* [ESPG codes](https://support.virtual-surveyor.com/en/support/solutions/articles/1000261353-what-is-an-epsg-code-) are often used to refer to different coordinate reference systems
* Most spatial data formats (shapefiles, rasters, etc) store the geographic coordinate system with the data, so users only need to worry about this if they wish to switch the Geographic Coordinate Reference System to match that of another spatial dataset. 
Additional information about Geographic Coordinate Systems (where the data is located on earth) and Projected Coordinate Systems (how the data is drawn on a flat surface) can be found [here](https://www.esri.com/arcgis-blog/products/arcgis-pro/mapping/gcs_vs_pcs).

#### Static Spatial Visualization
Often, we need to visualize data and/or forecasts distributed in geographic space. Here we list some static spatial visualization tools in R and Python which can be helpful to open, work with, and visualize spatial data. These packages and tools may help when dealing with issues specific to geospatial data, for example, opening geospatial file types, making maps with appropriate spatial projections, plotting different spatial data types including gridded raster data and polygons and other shapefiles.

Geospatial operations & tools for working with spatial data:
Many of the software programs commonly used in ecological forecasting have capabilities to work with geospatial data. Here we provide links to these resources and packages

**R**

* [Raster](https://cran.r-project.org/web/packages/raster/index.html) contains useful functions for working with, manipulating, and visualizing rasters in R. The R community is moving towards deprecating this tool in favor of Terra
* [Terra](https://cran.r-project.org/web/packages/terra/index.html) is primarily a faster version of the Raster package built by the same author but also handles some aspects of vector data. Currently suggested for use over raster, but may have some compatibility issues with other packages. The Raster package is [still suggested](https://gis.stackexchange.com/questions/413105/terrarast-vs-rasterbrick-for-loading-in-nc-files) when working with netCDF files that have multiple layers.
* [maps](https://cran.r-project.org/web/packages/maps/index.html) draws geographical maps
* [sf](https://cran.r-project.org/web/packages/sf/index.html) supports a standardized way to encode spatial vector data. Binds to 'GDAL' for reading and writing data, to 'GEOS' for geometrical operations, and to 'PROJ' for projection conversions and datum transformations.
* [sp](https://cran.r-project.org/web/packages/sp/index.html) Now [deprecated](https://twitter.com/edzerpebesma/status/1272928917700165633?s=20&t=teYNasm0f5dKabpt4IMpKg) in favor of the [sf](https://cran.r-project.org/web/packages/sf/index.html) package. This [wiki page](https://github.com/r-spatial/sf/wiki/Migrating) contains some equivalent commands between packages.
* [tmap](https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html) generates thematic maps. The syntax for creating plots is similar to that of ggplot2, but tailored to maps. 
* [ncdf4](https://cran.r-project.org/web/packages/ncdf4/index.html is a package for working with netCDF files in R
* [rgdal](https://cran.r-project.org/web/packages/rgdal/index.html) provides bindings to the 'Geospatial' Data Abstraction Library ('GDAL') (>= 1.11.4) and access to the projection/transformation operations from the 'PROJ' library. ***Note that 'rgdal' will be retired by the end of 2023*** so plan to transition to sf/stars/'terra' functions using 'GDAL' and 'PROJ' at your earliest convenience. 

**Python**

* [Rasterio](https://rasterio.readthedocs.io/en/latest/)
* [GeoPandas](https://geopandas.org/en/stable/)
* [Pysal](https://github.com/pysal)
* [Xarray:](https://xarray.pydata.org/en/stable/) useful for working with netCDF files 

#### Types of Plots for Spatial Data

1. A **choropleth map** links polygons (e.g., counties, states, etc.) to values of a variable in a dataset using color or symbols.
2. Proportional or graduated symbol maps use symbols scaled either proportionally to values of a variable or based on classifications of a variable
3. A **dot map** uses points to show the distribution of data spatially. Dots can be either at specific xy coordinates, or evenly distributed within an area of interest depending on the intent.
4. An **isopleth map** uses contours to connect identical values on a map and show the distribution of a variable spatially
5. **Cartograms** are maps that scale polygons (e.g., counties, states, etc.) based on the values of a variable. Similar conceptually to a proportional symbol map, but the underlying map features themselves are scaled instead of a point layer on top
6. **Dasymetric maps** type refine chloropleth maps using additional information to make the spatial distribution of mapped values more accurate
7. Reference: [https://www.cdc.gov/dhdsp/maps/gisx/resources/thematic-maps.html](https://www.cdc.gov/dhdsp/maps/gisx/resources/thematic-maps.html) 
 
#### Interactive Spatial Visualization
Many spatial datasets contain additional dimensions that you want to represent in your visualization. For example (could include a specific forecast example here) a dataset might have both spatial and temporal information, and you want to visualize how the geographic patterns in the data change over time, or visualize how different scenarios can change geographic distribution of your data. These tools provide some capability to create interactive spatial visualization:

**Tools to create maps:**

Here is a list of resources commonly used to plot rasters and shapefiles

* [ArcGIS](https://www.esri.com/en-us/arcgis/about-arcgis/overview)
* [QGIS](https://www.qgis.org/en/site/) is free and open source
* R
  + [Shiny](https://shiny.rstudio.com/) - R package to create interactive web apps including maps
  + [Plotly](https://plotly.com/r/) - a graphing library in R that can be used to make maps
  + [geom_sf()](https://ggplot2.tidyverse.org/reference/ggsf.html) for [ggplot2](https://ggplot2.tidyverse.org/)
  + [rasterVis](https://oscarperpinan.github.io/rastervis/) package to plot rasters more effectively in R
* [PYSAL](https://pysal.org/)
* [Leaflet](https://rstudio.github.io/leaflet/) is an open-source javaScript library for interactive maps. Leaflet can be used on its own or with Shiny.
* [Mapbox](https://www.mapbox.com/) provides interactive spatial forecasts (i.e. user inputs spatial location and type of management change the forecasts outputs)
* [Panoply](https://www.giss.nasa.gov/tools/panoply/) is a stand alone netcdf visualizer for local or remote catalogs

### Uncertainty Visualization
Communicating forecast uncertainty can play a critical role in both aiding decision-makers and building and maintaining public trust. When depicting uncertainty, it is important to consider the audience, their numeracy, and their level of training in statistics. Below we briefly discuss several methods for visualizing uncertainty and present tools that can be used to implement each.

* **Error bars** are commonly used to depict uncertainty in the scientific community. When using error bars, it is important to clearly specify what the error bar represents, since error bars can be used to represent different measures of uncertainty (e.g. standard deviations, standard errors, confidence intervals, prediction intervals). Because interpreting many of these uncertainty measures requires a firm grasp of statistics, using error bars can lead to misinterpretation or inappropriate inference, especially by lay audiences (Hofman et al., 2020; Joslyn & LeClerc, 2012; [Franconeri et al., 2021](https://doi.org/10.1177/15291006211051956)).
  + [`geom_errorbar`](https://ggplot2.tidyverse.org/reference/geom_linerange.html) in [ggplot2](https://ggplot2.tidyverse.org/)
  + [`geom_ribbon`](https://ggplot2.tidyverse.org/reference/geom_ribbon.html) in [ggplot2](https://ggplot2.tidyverse.org/) - analogous to an error bar but for lines rather than points
  + `point_interval` from [ggdist](https://mjskay.github.io/ggdist/) package
* Depicting a full **distribution** rather than summarizing it using an error bar can be an effective way of visualizing uncertainty. Compared to error bars, distribution visualizations provide the viewer with more information and have been linked to better decision making [Franconeri et al., 2021](https://doi.org/10.1177/15291006211051956). See the Distributions section above for tools - ***NEED TO PUT IN THE LINK TO THIS WHEN THE PAGE IS MADE***
* Uncertainty can also be mapped to different visual channels, including color value or **luminance, fuzziness, size, transparency, and location** (MacEachren et al., 2012). These channels can be particularly useful when both x and y positions are already being used to represent another aspect of the data (e.g. on a map). However, these visual channels are less precise than encoding uncertainty with position, as in the case of error bars and distributions [Franconeri et al., 2021](https://doi.org/10.1177/15291006211051956).
  + In ggplot the `aes()` function can be used to map the fill, size, and alpha aesthetics to uncertainty. 
  + Uncertainty can be mapped to fuzziness using the `with_blur()` function from [ggfx](https://ggfx.data-imaginist.com/) package
* **Value-suppressing uncertainty palettes** leverage the fact that color hues are easier to tell apart when they are saturated and darker (Correll et al., 2018). Such palettes map a variable of interest to color hue, and uncertainty to color saturation and luminance. The result is that values associated with high levels of uncertainty are more difficult to ascertain. Value-suppressing uncertainty palettes can be applied to visualizations like choropleth maps and heatmaps.
  + [multiscales](https://github.com/clauswilke/multiscales) package in R
* Another approach to visualize uncertainty is to re-framing probabilities (e.g. 10%) as frequencies (e.g. 1 in 10). This can be an effective way to communicate uncertainty to a broader audience, including individuals with low numeracy.  ([Peters et al., 2010](https://journals.sagepub.com/doi/full/10.1177/0272989X10391672); [Franconeri et al., 2021](https://doi.org/10.1177/15291006211051956)). Several plot types take advantage of this so-called **“frequency-framing”** approach, which allows viewers to infer probability from visual representations of frequency: 
  + **Quantile dotplots** depict distributions by representing individual quantiles of the data as dots. Quantile dotplots have been shown to aid people in making decisions in the face of uncertainty ([Kay et al, 2016](https://dl.acm.org/doi/10.1145/2858036.2858558)).
    +`stat_dots` from the ggdist package produces a quantile dotplot if the quantiles argument is specified.
  + **Icon arrays** depict ratios with a frequency-frame by depicting a large number of icons and coloring them according to one or more variables.
    + [riskyr](https://hneth.github.io/riskyr) package
    + [ggwaffle](https://github.com/liamgilbey/ggwaffle) package
  + Visualizing individual data points, ensemble members, or samples from a distribution can convey uncertainty more intuitively while providing a more nuanced representation of the data underlying a distribution.([Weissgerber et al 2015](https://doi.org/10.1371/journal.pbio.1002128); [Franconeri et al., 2021](https://doi.org/10.1177/15291006211051956))
    + `geom_jitter` in ggplot can be used to avoid overplotting when plotting several individual data points 
  + **Hypothetical outcome plots** (or HOPs) are animated sequences of plots where each plot represents a random draw from an underlying distribution. Research suggests that HOPs lead to better understanding of uncertainty and more accurate judgments about differences between multiple random variables ([Hullman et al., 2015](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0142444); [Kale et al., 2019](https://ieeexplore.ieee.org/document/8440816)).
    + See tools for animated visuals above ***NEED TO PUT IN THE LINK TO THIS WHEN THE PAGE IS MADE***

#### References and other Resources
* [Fundamentals of Data Visualization](https://clauswilke.com/dataviz/visualizing-uncertainty.html) - section 16 specifically discusses visualizing uncertainty
* [The Science of Visual Data Communication](https://journals.sagepub.com/stoken/default+domain/10.1177%2F15291006211051956-FREE/full) - an overview of approaches to uncertainty visualization
* [ggdist](https://mjskay.github.io/ggdist/) package
* [ungeviz](https://github.com/wilkelab/ungeviz) package 
* [Recording](https://youtu.be/LTSKrtyzALM) of a panel hosted by the EFI Social Science Working group on visualizing uncertainty in forecasts including the use of color in NOAA weather maps

